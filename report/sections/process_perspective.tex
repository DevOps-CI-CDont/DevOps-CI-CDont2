\section{Process' Perspective}
% SECTION PURPOSE: In essence it has to be clear how code or other artifacts come from idea into the running system and everything that happens on the way.

\subsection{Developer interaction}
The team met at every lecture and exercise session, where a plan was discussed on how to reach the goal of the following weeks exercises. This plan was then carried out between the developers. In order to work asynchronously, we also decided to use Discord as an online communication tool. The reason this was chosen, was due to the ease of creating a group channel, where all members could write their topics and update, whilst also being able to join voice calls and share individuals screens. 
\\
Another choice we could have made was to use Microsoft Teams, as this is also how the course provides news and discussions. We opted not to use teams, as all members were more comfortable with Discord and had accounts.

\subsection{Organization of team}\label{subsec:organization_of_team}
The team had to manage DevOps practices, Frontend and backend development. The team was not built with generalists, but rather specialists in the frontend and backend departments.
\begin{itemize}
    \item \textbf{DevOps:} Other than migrating the old "minitwit" application into a modern framework, most of the work thereafter was done in devops practices, including monitoring, CI/CD pipelines and more. All developers were responsible for working and implementing the changing feature requirements, provided by the course.
    \item \textbf{Frontend:} 1 of the team members was assigned to the frontend, redesigning the entire application to use a modern frontend framework (Next.js), along with updating dependencies and improving the UI and UX of the application.
    \item \textbf{Backend:} 3 of the team members worked on the backend, migrating the application from a Python flask API into a Go:GIN application.
\end{itemize}
\subsection{Full stage \& tool description of CI/CD Chains}
\subsubsection{Continuous integration}\label{subsubsec:ci}
We built a continuous integration(CI) workflow\cite{DevOps-CI-CDont} that would serve as a quality gate when pushing new changes. As the main focus of Minitwit was to handle requests from the simulator our tests only related to the backend and no end-to-end tests exist.\\\\
When a push or pull-request is accepted into the main branch, a virtual machine (VM) "Runner" is spun up, by Github getting everything it needs as secrets through GitHub's built-in "Github secrets"\cite{GitHub-Secrets}. \\ 
Once the machine is ready, it builds a test-specific Dockerfile that mimics our real Dockerfile but instead connects to a test database rather than production. DigitalOcean's command line tool "Doctl"\cite{DigitalOcean-doctl} is installed, and our new image is pushed to a container registry on  DigitalOcean.\\\\
After this job, our API is running on the "runner" and testing can begin. Testing happens in a new job, which also installs doctl, and then it pulls the "testing-image" the other job uploaded, runs the image and runs all go tests. Finally, a static code analysis job runs, that installs all dependencies and runs typescript type checking "tsc", "eslint", and "go vet". If any of these steps fail, the job fails and the workflow as a whole exits with a "Failure". 
\subsubsection{Continuous deployment}
To support frequent delivery of new versions of Minitwit we also created a continuous deployment (CD) workflow on Github actions. The workflow runs any time the CI workflow completes successfully. The workflow then builds the backend and frontend images (using the necessary secrets stored in GitHub secrets), before installing doctl and pushing the images to the container registry.\\\\
The DigitalOcean Droplet needs to know when an update exists for  one of the images. For this purpose, we use "Watchtower"\cite{watchtower}. Watchtower monitors running docker containers and watches for any updates for images used in running containers. If any images are updated watchtower will pull that update and restart the container using the new image. Watchtower is configured to look for image updates every 60 seconds. The combination of the previous workflow and watchtower means that any new code on the main branch (that passes the quality gates) also updates our "production" environment. 

\subsection{Organization of repository}
% describe the structure of mono-repository 
We decided to structure the repository as a monorepo. We had 2 projects in the repo concerning a frontend project in Next.js and a backend project in Go. The reason we decided for this structure, is that a monorepo allows us to sync releases from one main repository. Meaning every time there is a release, then all of the code is at the same state. Monorepos are useful when the codebase is not too large, meaning we do not have thousands of files and or packages in the codebase, slowing down each pull, commit and push.
\\\\
When building microservices a polyrepo may seem the natural choice, however, the monorepo allowed us to create a unified and automated CI/CD pipeline, that can avoid many issues associated with polyrepos, such as not being in the same state \cite{monorepo_pros}. 

\subsection{Applied branching strategy}\label{subsec:branching_strategy}
At the project kick-off, we did not have a branching strategy, meaning all development was done on a "Dev" branch, that all developers were working on. This did not cause a lot of issues, as all commits and pushes were short in terms on modified lines of code, leading to no merge conflicts.
\\\\
Later in the project, we developed a dedicated branching strategy, following the trunk-based strategy \cite{branching_strategy}. This strategy works well for small teams, as it focuses on keeping the master in a deployable state. Commits to master are not frowned upon as the aim is that any fatal errors will be caught by CI. For bigger changes, feature branches can be made but they must be shortlived and rebased if development takes too long. 

\subsection{Applied development process}
We used Github's built-in issue tracking system, eventually also using those issues inside a Kanban-like board via a Github "Project" for the Github organization we had. At the end, we had 4 columns in the board (Todo, In Progress, Done and Unprioritized). Unprioritized contained all the tasks that we found would be realistic/interesting tasks for the project if it were to continue. 
\subsection{Monitoring}
% How do you monitor your systems and what precisely do you monitor?
For our monitoring setup we utilize Prometheus \& Grafana. A Prometheus container scrapes our backend api for metrics on a fixed time interval, and the metrics are visualized by grafana which queries Prometheus. In Grafana we have a single main dashboard with two graphs, specifically graphs for memory usage (\%) and endpoint counter, which can be seen on \autoref{fig:grafana}.
\\\\
For the endpoint counter we gather the metrics using middleware, that gets executed after every request. Here's how we use Gin to register endpoint usage:
\begin{verbatim}
...
Router.GET("/metrics", gin.WrapH(promHandler))
Router.GET("/mytimeline", getTimeline, incrementCounter(m, "/mytimeline"))
Router.GET("/public", getPublicTimeline, incrementCounter(m, "/public"))
...
\end{verbatim}
The \textit{incrementCounter} function is a helper function, which returns a "gin.Handlerfunc", which will increment the appropriate endpoint count once triggered e.g. "/mytimeline".
\\\\
For recording the memory usage, we have a "goroutine" in the background which records the current memory usage every 10 seconds. Prometheus scrapes our API for this information from the "/metrics" endpoint at a fixed interval.
\\\\

\begin{figure}[H]
    \centering
    \includegraphics[scale=0.35]{report/diagrams/grafana_example.png}
    \caption{The grafana dashboard after executing some requests to the /public, /login, and /register endpoints.}
    \label{fig:grafana}
\end{figure}
\subsection{Logging}
% What do you log in your systems and how do you aggregate logs?
Our logging system consists of an EFK stack, i.e. elasticsearch, filebeat and kibana. Filebeat captures and ships the logs from standard out to  elasticsearch, and kibana is the user interface that allows us to retrieve the logs. As we did not implement docker swarm/load balancing, there was no log aggregation from different sources. \\

\subsection{Security assessment}
% Brief results
The exercises for lecture 9 was to do a security assessment of the minitwit application. Our peer group sadly did not leave an assessment of our website, which is why we did it ourselves. For this, we used Skipfish \cite{skipfish}. Skipfish is a security reconnaissance tool, that gives an output of potential security risks. Running this tool on our website didn't bring any interesting results \footnote{Skipfish results: \url{https://github.com/DevOps-CI-CDont/DevOps-CI-CDont/tree/main/CICdont3.html}}.
\\\\
A security assessment of our website:
\begin{enumerate}
    \item \textbf{HTTPS}: The website does not support HTTPS. For a short moment, we had a SSL certificate set up through Cloudflare, such that all traffic was considered safe. This caused an issue for all the API calls, which were hosted on a port that was not on HTTPS, but rather HTTP. HTTPS states that you cannot make calls to non-secure HTTP sites, meaning that all our API calls failed. Due to time restrictions, we were unable to fix this issue, which is why the website is still hosted on HTTP.
    \item \textbf{SQL injection}: The frontend handles user logins and signup and more through input fields, which are sent directly to the backend API. In the backend, strings are never executed directly against the database, instead, an ORM interface sits between the user and the database, this makes it impossible for the user to inject SQL. 
    \item \textbf{Packages}: When dealing with external packages and dependencies, we may be subject to a zero-day exploit. If there is discovered an XSS, prototype pollution or other kinds of attacks in a package, then we are vulnerable until a fix is created. For npm packages, we can run an audit, to check state of direct and indirect dependencies. Running an audit as of the handin date, there are no security risks with external packages.
    \item \textbf{Authentication}: One of the biggest risks in our application is the authentication system. Currently, when you login in the frontend, the backend sends your user ID back which is then set as a \verb|user_id| cookie. This is not optimal, as any user can login as any other user, by simply changing the \verb|user_id| cookie. A better way of doing this would be to implement JSON Web Tokens (JWT) \cite{jwt}, but again, due to time restrictions, this was discarded.
\end{enumerate}

\subsection{Applied strategy for scaling and load-balancing}
Our scaling has only been vertical: increasing resources for CPU, RAM, and Disk on a single Virtual Machine (Droplet). It has also been manual, meaning we have to notice resource usage on the droplet and go into DigitalOcean to upscale resources (during which the Droplet must be turned off). We had configured some resource alerts in DigitalOcean (Memory Usage percent and CPU utilization percent, sending an email if either is above 85\% for 15 minutes or longer). \\
We didn't implement Docker Swarm as a scaling/load-balancing measure.

\subsection{AI assistants}
% Reflect how it supported/hindered your process.
We have used Github Copilot via its VSCode extension.
A couple of areas where it was memorably useful:
\begin{enumerate}
    \item writing out repetitive patterns in the API (eg. error handling in Go, checking for certain parameters/cookies).
    \item writing fetch requests from the frontend (it seems to understand well how to use the endpoints that are described in the same repository).
    \item writing utility functions (Copilot is especially effective if given a perfectly descriptive function name, even better if standard terminology is used)
\end{enumerate} 
One challenge of using Copilot with an unfamiliar language (such as Go was to all of us), is that it can be really hard to tell if a suggestion is correct. Even if something seems to work as intended, it is still important to understand the code. \\\\
Another "AI Assistant" we have used is ChatGPT. A couple of areas where it was memorably useful: 
\begin{enumerate}
    \item Suggesting and explaining nginx configurations
    \item Debugging CORS errors, suggesting fixes with middleware in Go backend.
    \item Debugging memory usage problems. 
    \item Generating commands for iptables configuration.
\end{enumerate}
The conversational design is quite nice to be able to "tweak" its suggestions. It often spits out large blocks of code that aren't quite what you want, but it can fix that if told what to tweak. \\
A downside is that it may \textit{hallucinate} commands, flags, and functions that seem very plausible and one may think "How great! That command is exactly what I want", and then it doesn't exist. \\
When asked to use the functionality of a library, it will tend to use it in the way that there is most content like on the internet - this means the newest "best practices" aren't as likely to be used as whatever is still most common in the training data.  